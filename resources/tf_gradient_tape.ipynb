{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_gradient_tape.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLXtoMFhU5AS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## reference\n",
        "\n",
        "# https://medium.com/analytics-vidhya/tf-gradienttape-explained-for-keras-users-cc3f06276f22"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMQ5Rk8SSYHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6c5_eYHSfKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d784ea5d-1006-484e-869f-a7dd013b1da4"
      },
      "source": [
        "## test tf.GradientTape\n",
        "\n",
        "x = tf.constant(5.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(x)\n",
        "    y = x ** 3\n",
        "\n",
        "print(tape.gradient(y, x).numpy())\n",
        "print(3 * x ** 2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75.0\n",
            "tf.Tensor(75.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyh2LgXeSiKd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2f6c8c3-37e5-42a5-d85d-b28f9be43b7c"
      },
      "source": [
        "x = tf.Variable(6.0, trainable = True)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = x ** 3\n",
        "\n",
        "print(tape.gradient(y, x).numpy())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "108.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFj0jvbpSs9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.Variable(6.0, trainable = False)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y = x ** 3\n",
        "\n",
        "# print(tape.gradient(y, x).numpy())\n",
        "# AttributeError: 'NoneType' object has no attribute 'numpy'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAI7YpRKTLWr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3806c3f1-78e8-4a79-99c5-641ca0df7911"
      },
      "source": [
        "## higher order derivatives\n",
        "\n",
        "x = tf.Variable(3.0, trainable = True)\n",
        "\n",
        "with tf.GradientTape() as tape1:\n",
        "    with tf.GradientTape() as tape2:\n",
        "        y = x ** 3\n",
        "    order_1 = tape2.gradient(y, x)\n",
        "order_2 = tape1.gradient(order_1, x)\n",
        "\n",
        "print(order_2.numpy())\n",
        "print(3 * x ** 2)\n",
        "# differentiate x ** 3 two times with respect to x\n",
        "print(3 * 2 * x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18.0\n",
            "tf.Tensor(27.0, shape=(), dtype=float32)\n",
            "tf.Tensor(18.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ3vLYJ0WPqa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fc87815f-db77-455a-a552-170bf7647c41"
      },
      "source": [
        "## persistent\n",
        "\n",
        "a = tf.Variable(6.0, trainable = True)\n",
        "b = tf.Variable(2.0, trainable = True)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    y1 = a ** 2\n",
        "    y2 = b ** 3\n",
        "\n",
        "print(tape.gradient(y1, a).numpy())\n",
        "# below produces RuntimeError: GradientTape.gradient can only be called once on non-persistent tapes.\n",
        "# print(tape.gradient(y2, b).numpy())\n",
        "\n",
        "a = tf.Variable(6.0, trainable = True)\n",
        "b = tf.Variable(2.0, trainable = True)\n",
        "\n",
        "with tf.GradientTape(persistent = True) as tape:\n",
        "    y1 = a ** 2\n",
        "    y2 = b ** 3\n",
        "\n",
        "# take gradient with respect to a\n",
        "print(tape.gradient(y1, a).numpy())\n",
        "# take gradient with respect to b\n",
        "print(tape.gradient(y2, b).numpy())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.0\n",
            "12.0\n",
            "12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygqAHaZgU86S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16ae9495-83a1-4213-9790-29b4f1db06cd"
      },
      "source": [
        "## linear regression\n",
        "\n",
        "def loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Loss function\n",
        "    Compute L1 loss\n",
        "    \"\"\"\n",
        "    return tf.abs(y_true - y_pred)\n",
        "\n",
        "# training data\n",
        "x_train = np.asarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "# y = 10x + 5\n",
        "y_train = np.asarray([10 * i + 5 for i in x_train])\n",
        "lr = 0.001\n",
        "epochs = 1000\n",
        "\n",
        "# trainable variables which are trained in epochs\n",
        "a = tf.Variable(random.random(), trainable = True)\n",
        "b = tf.Variable(random.random(), trainable = True)\n",
        "\n",
        "def step(x_true, y_true):\n",
        "    with tf.GradientTape(persistent = True) as tape:\n",
        "        # forward pass\n",
        "        y_pred = a * x_true + b\n",
        "        # calculate loss\n",
        "        reg_loss = loss(y_true, y_pred)\n",
        "\n",
        "    # take gradient with respect to a and b\n",
        "    a_gradient, b_gradient = tape.gradient(reg_loss, (a, b))\n",
        "    # Update variables\n",
        "    a.assign_sub(a_gradient * lr)\n",
        "    b.assign_sub(b_gradient * lr)\n",
        "\n",
        "# training\n",
        "for _ in range(epochs):\n",
        "    step(x_train, y_train)\n",
        "\n",
        "print(f'y = {a.numpy()} x + {b.numpy()}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y = 9.998836517333984 x + 4.990261077880859\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}