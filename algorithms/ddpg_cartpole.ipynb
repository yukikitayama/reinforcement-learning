{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ddpg_cartpole.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg9tD72-9YQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## setup\n",
        "\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdsT6NnA9mXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## hyperparameters\n",
        "\n",
        "# https://gym.openai.com/envs/Pendulum-v0/\n",
        "ENV = 'Pendulum-v0'\n",
        "THETA = 0.15\n",
        "DT = 1e-2\n",
        "BUFFER_CAPACITY = 100000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmabnznf9yzd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "7ba5b898-fcdb-4282-9456-ba60f253684e"
      },
      "source": [
        "## environment\n",
        "\n",
        "env= gym.make(ENV)\n",
        "\n",
        "num_states = env.observation_space.shape[0]\n",
        "num_actions = env.action_space.shape[0]\n",
        "upper_bound = env.action_space.high[0]\n",
        "lower_bound = env.action_space.low[0]\n",
        "\n",
        "print(f'state space: {num_states}')\n",
        "print(f'action space: {num_actions}')\n",
        "print(f'continuous action max: {upper_bound}')\n",
        "print(f'continuous action min: {lower_bound}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state space: 3\n",
            "action space: 1\n",
            "continuous action max: 2.0\n",
            "continuous action min: -2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suuHxDw3_b88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## ornstein-uhlenbeck process\n",
        "\n",
        "class OUActionNoise:\n",
        "    \"\"\"\n",
        "    Ornstein-Uhlenbeck process models the exploration noise process\n",
        "    Use temporally correlated noise in order to explore well \n",
        "    in physical environments that have momentum.\n",
        "    In paper, theta = 0.1g, sigma = 0.2\n",
        "    \n",
        "    https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process\n",
        "\n",
        "    dt = derivative of t, time\n",
        "    \"\"\"\n",
        "    # x_initial?\n",
        "    def __init__(self, mean, std, theta = THETA, dt = DT, x_initial = None):\n",
        "        self.theta = theta\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.dt = dt\n",
        "        self.x_initial = x_initial\n",
        "        self.reset()\n",
        "\n",
        "    def __call__(self):\n",
        "        x = (\n",
        "            self.x_prev\n",
        "             + self.theta * (self.mean - self.x_prev) * self.dt\n",
        "             + self.std * np.sqrt(self.dt) * np.random.normal(size = self.mean.shape)\n",
        "        )\n",
        "        # it makes next noise dependent on current noise\n",
        "        self.x_prev = x\n",
        "        return x\n",
        "\n",
        "    def reset(self):\n",
        "        # default x_initial is None\n",
        "        if self.x_initial is not None:\n",
        "            self.x_prev = self.x_initial\n",
        "        else:\n",
        "            self.x_prev = np.zeros_like(self.mean)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUNoTtmKKXeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## experience replay buffer\n",
        "\n",
        "class Buffer:\n",
        "    \"\"\"\n",
        "    Experience replay buffer\n",
        "    \"\"\"\n",
        "    def __init__(self, buffer_capacity = BUFFER_CAPACITY, batch_size = BATCH_SIZE):\n",
        "        self.buffer_capacity = buffer_capacity\n",
        "        self.batch_size = batch_size\n",
        "        # initialize buffer_counter which is incremented by record method\n",
        "        self.buffer_counter = 0\n",
        "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
        "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
        "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
        "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
        "\n",
        "    def record(self, obs_tuple):\n",
        "        \"\"\"\n",
        "        When buffer_counter > buffer_capacity,\n",
        "        index has a new index starting from 0 by %\n",
        "        \"\"\"\n",
        "        index = self.buffer_counter % self.buffer_capacity\n",
        "        self.state_buffer[index] = obs_tuple[0]\n",
        "        self.action_buffer[index] = obs_tuple[1]\n",
        "        self.reward_buffer[index] = obs_tuple[2]\n",
        "        self.next_state_buffer[index] = obs_tuple[3]\n",
        "        self.buffer_counter += 1\n",
        "\n",
        "    def learn(self):\n",
        "        \"\"\"\n",
        "        This method computes the loss and update the parameters\n",
        "        \"\"\"\n",
        "        record_range = min(self.buffer_counter, self.buffer_capacity)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}